{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data.dataset import Dataset, TensorDataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from DiacriticDataset import DiacriticDatasetShaddah\n",
    "import pickle\n",
    "from scipy.sparse import csr_matrix\n",
    "import numpy as np\n",
    "from scipy.optimize import fmin_l_bfgs_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DiacriticDatasetShaddah('Dataset_with_shaddah/train_cleaned_withshadda_215.txt','Dataset_with_shaddah/letter_to_id.pickle','Dataset_with_shaddah/id_to_letter.pickle','Dataset_with_shaddah/diacritic_to_id.pickle','Dataset_with_shaddah/id_to_diacritic.pickle','Dataset_with_shaddah/word_to_id.pickle','Dataset_with_shaddah/id_to_word.pickle','Dataset/diacritic_to_id.pickle','Dataset/id_to_diacritic.pickle','Dataset_with_shaddah/word_to_id_withdiacritics.pickle','Dataset_with_shaddah/id_to_word_withdiacritics.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset)\n",
    "Y = train_dataset.id_to_diacritic.keys()\n",
    "with open('Dataset_with_shaddah/diacritic_to_id_memm.pickle','rb') as file:\n",
    "    diacritic_to_id_memm = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_Lprime(v,*args):\n",
    "    lamda = args[0]\n",
    "    training_matrix = None #must fill\n",
    "    num_of_features = None #must fil\n",
    "    first_summerand_L= training_matrix.dot(v).sum()\n",
    "    second_summerand_L  = 0\n",
    "    \n",
    "    first_summerand_Lprime = np.array(training_matrix.sum(axis=0))[0]\n",
    "    second_summerand_Lprime = csr_matrix((1, num_of_features), dtype=np.int8)\n",
    "\n",
    "    for training_example in train_dataloader:\n",
    "        letters = training_example[0][0].tolist()\n",
    "        diacritics = training_example[1][0].tolist()\n",
    "        \n",
    "        for position,letter in enumerate(letters):\n",
    "            inner_summation = 0\n",
    "            \n",
    "            if position==0:\n",
    "                history = History(diacritic_to_id_memm['*'],diacritic_to_id_memm['*'],letters,position)\n",
    "            if position==1:\n",
    "                history = History(diacritics[position-1],diacritic_to_id_memm['*'],letters,position)\n",
    "            else:\n",
    "                history = History(diacritics[position-1],diacritics[position-2],letters,position)\n",
    "            \n",
    "            feature_summation = csr_matrix((1, num_of_features), dtype=np.int8)\n",
    "            for tag in Y:\n",
    "                features = generate_features(history,tag)\n",
    "                \n",
    "                dot_product = np.exp(features.dot(v))[0]\n",
    "                \n",
    "                feature_summation += features*dot_product\n",
    "                \n",
    "                \n",
    "                inner_summation += dot_product\n",
    "                \n",
    "                \n",
    "            second_summerand_L += np.log(inner_summation)   \n",
    "            \n",
    "            feature_summation /= inner_summation\n",
    "            \n",
    "            second_summerand_Lprime += feature_summation\n",
    "    \n",
    "    regularization = (lamda/2)*np.inner(v,v)\n",
    "    regularization_prime = lamda*v\n",
    "    L = -(first_summerand - second_summerand-regularization)     \n",
    "    Lprime = -(first_summerand_Lprime-second_summerand_Lprime.toarray()[0]-regularization_prime)\n",
    "    return L,Lprime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_features = None #must fill\n",
    "lamda = 1\n",
    "maxiterations = 1\n",
    "_iprint = 1\n",
    "v0 = np.random.rand(num_of_features)\n",
    "v_optimal,f,d = fmin_l_bfgs_b(func=L_Lprime,x0=v0,fprime=None,args=(lamda),maxiter=maxiterations,iprint=_iprint)\n",
    "weights = v_optimal[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_matrix = csr_matrix([[1, 2, 0], [0, 0, 3], [4, 0, 5]])\n",
    "v = np.array([1, 0, -1])\n",
    "num_of_features = 3\n",
    "second_summerand_Lprime = csr_matrix((1, num_of_features), dtype=np.int8)\n",
    "feature_summation= csr_matrix((1, num_of_features), dtype=np.int8)\n",
    "test = [csr_matrix([[1, 2.5, 0]]),csr_matrix([[1, 2, 0]])]\n",
    "first_summerand_L= training_matrix.dot(v).sum()\n",
    "second_summerand_L  = 0\n",
    "\n",
    "first_summerand_Lprime = np.array(training_matrix.sum(axis=0))[0]\n",
    "second_summerand_Lprime = csr_matrix((1, num_of_features), dtype=np.int8)\n",
    "inner_summation = 0\n",
    "for features in test:\n",
    "    dot_product = np.exp(features.dot(v))[0]\n",
    "    feature_summation += features*dot_product\n",
    "    inner_summation += dot_product\n",
    "    \n",
    "second_summerand_L += np.log(inner_summation)\n",
    "feature_summation /= inner_summation\n",
    "second_summerand_Lprime += feature_summation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.  , 2.25, 0.  ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_summerand_Lprime.toarray()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
