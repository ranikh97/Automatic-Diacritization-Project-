{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.utils.data.dataset import Dataset, TensorDataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from DiacriticDataset import DiacriticDatasetShaddah\n",
    "import pickle\n",
    "from collections import Counter\n",
    "from itertools import product\n",
    "from collections import defaultdict\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = DiacriticDatasetShaddah('Dataset_with_shaddah/test_cleaned_withshadda_215.txt','Dataset_with_shaddah/letter_to_id.pickle','Dataset_with_shaddah/id_to_letter.pickle','Dataset_with_shaddah/diacritic_to_id.pickle','Dataset_with_shaddah/id_to_diacritic.pickle','Dataset_with_shaddah/word_to_id.pickle','Dataset_with_shaddah/id_to_word.pickle','Dataset/diacritic_to_id.pickle','Dataset/id_to_diacritic.pickle','Dataset_with_shaddah/word_to_id_withdiacritics.pickle','Dataset_with_shaddah/id_to_word_withdiacritics.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi(letter_sequence,q,e):\n",
    "    \"\"\"\n",
    "    :param letter_sequence:List  A sequence of letter ids\n",
    "    :param q: transition probabilities\n",
    "    :param e: emission probabilities\n",
    "    :return:List a sequence of tag ids\n",
    "    \"\"\"\n",
    "    pi = {}\n",
    "    bp = {}\n",
    "    pi[(-1,'*','*')] = 1\n",
    "    num_of_letters = len(letter_sequence)\n",
    "    tag_sequence = [0]*num_of_letters\n",
    "    for k in range(num_of_letters):\n",
    "        if k==0:\n",
    "            s_u = ['*']\n",
    "            s_v = list(range(16))\n",
    "            s_w =['*']\n",
    "        elif k==1:\n",
    "            s_u = list(range(16))\n",
    "            s_v = list(range(16))\n",
    "            s_w = ['*']\n",
    "        else:\n",
    "            s_u = list(range(16))\n",
    "            s_v = list(range(16))\n",
    "            s_w = list(range(16))\n",
    "            \n",
    "        for u in s_u:\n",
    "            for v in s_v:\n",
    "                probs = []\n",
    "                for w in s_w:\n",
    "                    probs.append(pi[(k-1,w,u)]*q[v,w,u]*e[letter_sequence[k],v])\n",
    "                    \n",
    "                max_prob = max(probs)\n",
    "                pi[(k,u,v)] = max_prob\n",
    "                bp[(k,u,v)] = s_w[probs.index(max_prob)]\n",
    "                \n",
    "    max_u = 0\n",
    "    max_v = 0\n",
    "    max_value = 0\n",
    "    s = list(range(16))\n",
    "    for u in s:\n",
    "        for v in s:\n",
    "            if (pi[(num_of_letters-1,u,v)]*q['STOP',u,v])>max_value:\n",
    "                max_value = (pi[(num_of_letters-1,u,v)]*q['STOP',u,v])\n",
    "                max_u = u\n",
    "                max_v = v\n",
    "    tag_sequence[num_of_letters-1] = max_v\n",
    "    tag_sequence[num_of_letters-2] = max_u\n",
    "\n",
    "    for k in reversed(range(num_of_letters-2)):\n",
    "        tag_sequence[k] = bp[(k+2,tag_sequence[k+1],tag_sequence[k+2])]\n",
    "\n",
    "\n",
    "    return tag_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1650/1650 [05:23<00:00,  5.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Diacritic Accuracy: 0.629\tTest Word Accuracy: 0.174783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with open('HMM_Model/transition_probabilities','rb') as file:\n",
    "    transitions = pickle.load(file)\n",
    "    \n",
    "with open('HMM_Model/emission_probabilities','rb') as file:\n",
    "    emissions = pickle.load(file)\n",
    "\n",
    "tp = 0\n",
    "total = 0\n",
    "    \n",
    "tp_word = 0\n",
    "total_word = 0\n",
    "\n",
    "wrong_words = []\n",
    "\n",
    "for i,test_example in enumerate(tqdm(test_dataloader)):\n",
    "    letters = test_example[0][0].tolist()\n",
    "    true_diacritics = test_example[1][0].tolist()\n",
    "    true_words = test_example[4][0].tolist()\n",
    "    predicted_diacritics = viterbi(letters,transitions,emissions)\n",
    "    \n",
    "    tp += (np.array(true_diacritics)==np.array(predicted_diacritics)).sum()\n",
    "    total += len(true_diacritics)\n",
    "    \n",
    "    sentence = ''\n",
    "    for index,letter_id in enumerate(letters):\n",
    "        letter = test_dataset.id_to_letter[letter_id]\n",
    "        diacritic = test_dataset.id_to_diacritic[predicted_diacritics[index]]\n",
    "        if letter_id==2:\n",
    "            sentence += \" \"\n",
    "            diacritic = \"\"\n",
    "        elif predicted_diacritics[index] == 3: \n",
    "            diacritic = \"\"\n",
    "\n",
    "        sentence += (letter+diacritic)\n",
    "\n",
    "\n",
    "    predicted_words = sentence.split()\n",
    "\n",
    "    for index,predicted_word in enumerate(predicted_words):\n",
    "        predicted_word_id = test_dataset.word_to_id_diacs.get(predicted_word,'NOT_FOUND')\n",
    "        if predicted_word_id != 'NOT_FOUND':\n",
    "            if predicted_word_id == true_words[index]:\n",
    "                tp_word += 1\n",
    "            else:\n",
    "                wrong_words.append(test_dataset.id_to_word_diacs[true_words[index]])\n",
    "        else:\n",
    "            wrong_words.append(test_dataset.id_to_word_diacs[true_words[index]])\n",
    "            continue\n",
    "\n",
    "\n",
    "    total_word += len(predicted_words)\n",
    "\n",
    "\n",
    "diacritic_accuracy = tp/total\n",
    "word_accuracy = tp_word/total_word\n",
    "print(\"Test Diacritic Accuracy: {:.3f}\\tTest Word Accuracy: {:3f}\".format(diacritic_accuracy,word_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142905"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
